"""hotlist probe backfill query generator."""
import argparse
import json
import os
import urllib.request

from google.cloud import bigquery
from jinja2 import Environment, PackageLoader

from bigquery_etl.format_sql.formatter import reformat

PROBE_INFO_SERVICE = (
    "https://probeinfo.telemetry.mozilla.org/firefox/all/main/all_probes"
)


def _build_probe_location(probe_name, metric_type, process, is_keyed):
    keyed_path = "keyed_" if is_keyed else ""
    probe_location = (
        f"payload.{keyed_path}{metric_type}s.{probe_name}"
        if process == "parent" and metric_type == "histogram"
        else f"payload.processes.{ process }.{metric_type}s.{ probe_name}"
    )
    return probe_location


def _get_all_processes_for_probe(project, probe_name, metric_type, is_keyed):
    client = bigquery.Client(project)
    table = client.get_table("telemetry_stable.main_v4")
    main_summary_schema = [field.to_api_repr() for field in table.schema]

    processes = []
    for item in main_summary_schema:
        if item["name"] == "payload":
            for field in item["fields"]:
                if metric_type == "histogram":
                    if (not is_keyed and field["name"] == "histograms") or (
                        is_keyed and field["name"] == "keyed_histograms"
                    ):
                        for subfield in field["fields"]:
                            if subfield["name"] == probe_name:
                                processes.append("parent")
                                break
                if field["name"] == "processes":
                    for process in field["fields"]:
                        if process["name"] in ["parent", "content", "gpu"]:
                            for probe_type_field in process["fields"]:
                                for subfield in probe_type_field["fields"]:
                                    if subfield["name"] == probe_name:
                                        processes.append(process["name"])
                                        break
    return processes


def _get_probe_details(probe_name):
    with urllib.request.urlopen(PROBE_INFO_SERVICE) as url:
        data = json.loads(url.read())

    for key in data.keys():
        metric_type = data[key]["type"]
        probe = key.replace(f"{metric_type}/", "").replace(".", "_").lower()
        if probe == probe_name:
            channel = "nightly"
            if "nightly" not in data[key]["history"]:
                channel = "beta"

                if "beta" not in data[key]["history"]:
                    channel = "release"
            data_details = data[key]["history"][channel][0]["details"]
            metric_kind = f'{data_details["kind"]}'
            is_keyed = data_details["keyed"]
            bucket_details = None
            if metric_type == "histogram":
                bucket_details = {
                    "n_buckets": int(eval(str(data_details["n_buckets"]))),
                    "min": int(eval(str(data_details["low"]))),
                    "max": int(eval(str(data_details["high"]))),
                }
            return (metric_type, metric_kind, bucket_details, is_keyed)
    raise Exception(f"Could not find probe {probe} from {PROBE_INFO_SERVICE}")


def render_main(probe_type, **kwargs):
    """Create a SQL query for backfilling a probe."""
    env = Environment(
        loader=PackageLoader("bigquery_etl", "glam/templates/hot_probe_backfill")
    )
    main_sql = env.get_template(f"glam_backfill_{probe_type}.sql")
    return reformat(main_sql.render(**kwargs))


def _gen_query_for_probe(probe_name, days, args) -> list[str]:
    """Generate queries for probe and return their locations."""
    backfill_days = args.days if args.days else days
    header = (
        "-- Query generated by: "
        "python3 -m bigquery_etl.glam.hotlist_probe_backfill "
        f"--source-table {args.source_table} "
        f"--probe_name {probe_name} "
        f"--days {backfill_days} "
        f"--process {args.process} "
        f"--project {args.project}"
    )

    (metric_type, metric_kind, bucket_details, is_keyed) = _get_probe_details(
        probe_name=probe_name
    )
    if metric_type not in ["histogram", "scalar"]:
        raise ValueError(f"Invalid metric type: {metric_type}")

    processes = (
        [args.process]
        if args.process != "all"
        else _get_all_processes_for_probe(
            args.project, probe_name, metric_type, is_keyed
        )
    )
    generated_queries = []
    for process in processes:
        probe_location = _build_probe_location(
            probe_name, metric_type, process, is_keyed
        )

        if metric_type == "scalar":
            query = render_main(
                "scalars",
                header=header,
                project=args.project,
                source_table=args.source_table,
                days=backfill_days,
                metric=probe_name,
                metric_type=metric_type,
                process=process,
                is_keyed=is_keyed,
                probe_location=probe_location,
            )

        elif metric_type == "histogram":
            query = render_main(
                "histograms",
                header=header,
                project=args.project,
                source_table=args.source_table,
                days=backfill_days,
                metric=probe_name,
                metric_kind=metric_kind,
                process=process,
                is_keyed=is_keyed,
                probe_location=probe_location,
                first_bucket=bucket_details["min"],
                last_bucket=bucket_details["max"],
                num_buckets=bucket_details["n_buckets"],
            )
        if args.query_folder_dest:
            out_folder = (
                f"{args.query_folder_dest}/{metric_type}/{probe_name}/{process}/"
            )
            os.makedirs(out_folder, exist_ok=True)
            out_file = f"{out_folder}query.sql"
            with open(out_file, "w") as f:
                f.write(query)
            # print(f"Saved query {out_file}")
            generated_queries.append(out_file)
        else:
            raise Exception(f"No file found {args.query_folder_dest}")
    return generated_queries


def _find_probes_to_backfill() -> list[tuple[str, int]]:
    """Return all probes that just made to the hotlist and need backfilling, \
    along with the amount of days to backfill.

    TODO:
    Call GLAM api to get 3 months of hotlist;
    Get probes that are on glam response but not currently on hotlist
    Get amount of days to backfill for (today - last_processed)
    Return backfill batch: probe_name: days
    """
    # Hardcoded for now
    return [("gc_ms", 180), ("findbar_shown", 180)]


def main():
    """Print a glam_backfill_histogram query to stdout."""
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--probe_name",
        type=str,
        help="Single probe to backfill. If empty \
        this script will find a list of new hot probes to backfill",
    )
    parser.add_argument(
        "--days",
        type=int,
        help="Number of days to backfill",
    )
    parser.add_argument(
        "--process",
        type=str,
        default="all",
        choices=["parent", "content", "gpu", "all"],
        help="Choice of process [parent, content, gpu, all].",
    )
    parser.add_argument(
        "--source_table",
        type=str,
        help="Name of the Source table",
        default="telemetry_derived.main_1pct_v1",
    )
    parser.add_argument(
        "--project",
        type=str,
        default="moz-fx-data-shared-prod",
    )
    parser.add_argument(
        "--query_folder_dest",
        type=str,
        help="Folder to store the backfill queries (1 per probe). \
            If not provided, this script will only print queries.",
    )
    args = parser.parse_args()

    probe_names = [args.probe_name] if args.probe_name else _find_probes_to_backfill()
    # print(f"Probes to backfill: {probe_names}")
    generated_queries = []
    for (probe_name, days) in probe_names:
        queries_loc = _gen_query_for_probe(probe_name, days, args)
        generated_queries += queries_loc

    for query in generated_queries:
        print(query)


if __name__ == "__main__":
    main()
